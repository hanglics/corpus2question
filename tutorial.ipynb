{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "corpus2question tutorial\n",
    "====================\n",
    "\n",
    "This notebook is a demo of how the `corpus2question` technique works and how can you apply it to your own corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic NLP-torch stack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /home/gsurita/.local/lib/python3.8/site-packages (1.5.0)\n",
      "Requirement already satisfied: transformers in /home/gsurita/.local/lib/python3.8/site-packages (3.0.2)\n",
      "Requirement already satisfied: tqdm in /home/gsurita/.local/lib/python3.8/site-packages (4.46.0)\n",
      "Requirement already satisfied: future in /usr/lib/python3/dist-packages (from torch) (0.18.2)\n",
      "Requirement already satisfied: numpy in /home/gsurita/.local/lib/python3.8/site-packages (from torch) (1.18.4)\n",
      "Requirement already satisfied: tokenizers==0.8.1.rc1 in /home/gsurita/.local/lib/python3.8/site-packages (from transformers) (0.8.1rc1)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /home/gsurita/.local/lib/python3.8/site-packages (from transformers) (0.1.91)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers) (2.22.0)\n",
      "Requirement already satisfied: sacremoses in /home/gsurita/.local/lib/python3.8/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: filelock in /home/gsurita/.local/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/gsurita/.local/lib/python3.8/site-packages (from transformers) (2020.5.14)\n",
      "Requirement already satisfied: packaging in /home/gsurita/.local/lib/python3.8/site-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: joblib in /home/gsurita/.local/lib/python3.8/site-packages (from sacremoses->transformers) (0.15.1)\n",
      "Requirement already satisfied: click in /home/gsurita/.local/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from sacremoses->transformers) (1.14.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/gsurita/.local/lib/python3.8/site-packages (from packaging->transformers) (2.4.7)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch transformers tqdm pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Download\n",
    "\n",
    "Download the pretrained model from it's repository and load it using the transformers library. corpus2question is based in doc2query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘t5-base.zip’ already there; not retrieving.\n",
      "\n",
      "Archive:  t5-base.zip\n",
      "  inflating: model.ckpt-1004000.data-00000-of-00002  \n",
      "  inflating: model.ckpt-1004000.data-00001-of-00002  \n",
      "  inflating: model.ckpt-1004000.index  \n",
      "  inflating: model.ckpt-1004000.meta  \n"
     ]
    }
   ],
   "source": [
    "! wget -nc https://storage.googleapis.com/doctttttquery_git/t5-base.zip\n",
    "! unzip -o t5-base.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/gsurita/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Iterable\n",
    "\n",
    "import nltk\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import T5Config, T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Define the target device. Use GPU if available.\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and load the QG model to the GPU. \n",
    "qg_tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "qg_config = T5Config.from_pretrained('t5-base')\n",
    "qg_model = T5ForConditionalGeneration.from_pretrained('model.ckpt-1004000', from_tf=True, config=qg_config)\n",
    "\n",
    "qg_model.to(device)\n",
    "\n",
    "True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation Pipeline\n",
    "\n",
    "Here we define our generation and preprocessing functions. Here you find the examples used in the paper, but you may customize these functions for your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(document: str, span=10, stride=5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Define your preprocessing function.\n",
    "    \n",
    "    This function should take the a corpus document and output a list of generation\n",
    "    spans. This is required so we can match the expected sequence size of the\n",
    "    generation model.\n",
    "    \"\"\"\n",
    "    \n",
    "    sentences = nltk.tokenize.sent_tokenize(document)\n",
    "    chunks = [\" \".join(sentences[i:i+span]) for i in range(0, len(sentences), stride)]\n",
    "\n",
    "    return chunks\n",
    "    \n",
    "\n",
    "\n",
    "def generate_questions(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Define your generation function. \n",
    "    \n",
    "    This function should take a text passage and generate a list of questions.\n",
    "    With the current configuration it always generate one question per passage.\n",
    "    \n",
    "    You may copy this example to use the same configuration as the paper. \n",
    "    You may also configure the generation parameters (such as using sampling and\n",
    "    generating multiple questions) for other use cases.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Append an end of sequence token </s> after the context.\n",
    "    doc_text = f\"{text} </s>\"\n",
    "\n",
    "    input_ids = qg_tokenizer.encode(doc_text, return_tensors='pt').to(device)\n",
    "    outputs = qg_model.generate(\n",
    "        input_ids=input_ids,\n",
    "        max_length=64,\n",
    "        do_sample=False,\n",
    "        n_beams=4,\n",
    "    )\n",
    "\n",
    "    return [qg_tokenizer.decode(output) for output in outputs]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide a corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section provides a corpus to the model. Here we provide an in-memory toy example, but you may read the text from other sources. We expect the corpus to be a list or iterable object of strings. You may also filter out non-natural language symbols before feeding the text into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    # Extracted from https://en.wikipedia.org/wiki/Lorem_ipsum\n",
    "    \"\"\"\n",
    "    In publishing and graphic design, Lorem ipsum is a placeholder text commonly used to demonstrate \n",
    "    the visual form of a document or a typeface without relying on meaningful content. Lorem ipsum \n",
    "    may be used before final copy is available, but it may also be used to temporarily replace copy \n",
    "    in a process called greeking, which allows designers to consider form without the meaning of the\n",
    "    text influencing the design.\n",
    "\n",
    "    Lorem ipsum is typically a corrupted version of De finibus bonorum et malorum, a first-century BC\n",
    "    text by the Roman statesman and philosopher Cicero, with words altered, added, and removed to make\n",
    "    it nonsensical, improper Latin.\n",
    "\n",
    "    Versions of the Lorem ipsum text have been used in typesetting at least since the 1960s, when it \n",
    "    was popularized by advertisements for Letraset transfer sheets. Lorem ipsum was introduced to the \n",
    "    digital world in the mid-1980s when Aldus employed it in graphic and word-processing templates for \n",
    "    its desktop publishing program PageMaker. Other popular word processors including Pages and Microsoft \n",
    "    Word have since adopted Lorem ipsum as well. \n",
    "    \"\"\",\n",
    "    \n",
    "    # Extracted from https://www.lipsum.com/\n",
    "    \"\"\"\n",
    "    Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the \n",
    "    industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and \n",
    "    scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap\n",
    "    into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the \n",
    "    release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing \n",
    "    software like Aldus PageMaker including versions of Lorem Ipsum.\n",
    "\n",
    "    It is a long established fact that a reader will be distracted by the readable content of a page when \n",
    "    looking at its layout. The point of using Lorem Ipsum is that it has a more-or-less normal distribution\n",
    "    of letters, as opposed to using 'Content here, content here', making it look like readable English. \n",
    "    Many desktop publishing packages and web page editors now use Lorem Ipsum as their default model text, \n",
    "    and a search for 'lorem ipsum' will uncover many web sites still in their infancy. Various versions have \n",
    "    evolved over the years, sometimes by accident, sometimes on purpose (injected humour and the like).\n",
    "\n",
    "    Contrary to popular belief, Lorem Ipsum is not simply random text. It has roots in a piece of classical \n",
    "    Latin literature from 45 BC, making it over 2000 years old. Richard McClintock, a Latin professor at \n",
    "    Hampden-Sydney College in Virginia, looked up one of the more obscure Latin words, consectetur, from a \n",
    "    Lorem Ipsum passage, and going through the cites of the word in classical literature, discovered the \n",
    "    undoubtable source. Lorem Ipsum comes from sections 1.10.32 and 1.10.33 of \"de Finibus Bonorum et Malorum\" \n",
    "    (The Extremes of Good and Evil) by Cicero, written in 45 BC. This book is a treatise on the theory of ethics, \n",
    "    very popular during the Renaissance. The first line of Lorem Ipsum, \"Lorem ipsum dolor sit amet..\", comes \n",
    "    from a line in section 1.10.32.\n",
    "    \n",
    "    The standard chunk of Lorem Ipsum used since the 1500s is reproduced below for those interested. Sections \n",
    "    1.10.32 and 1.10.33 from \"de Finibus Bonorum et Malorum\" by Cicero are also reproduced in their exact original\n",
    "    form, accompanied by English versions from the 1914 translation by H. Rackham.\n",
    "\n",
    "    There are many variations of passages of Lorem Ipsum available, but the majority have suffered alteration\n",
    "    in some form, by injected humour, or randomised words which don't look even slightly believable. If you are\n",
    "    going to use a passage of Lorem Ipsum, you need to be sure there isn't anything embarrassing hidden in the\n",
    "    middle of text. All the Lorem Ipsum generators on the Internet tend to repeat predefined chunks as necessary,\n",
    "    making this the first true generator on the Internet. It uses a dictionary of over 200 Latin words, combined \n",
    "    with a handful of model sentence structures, to generate Lorem Ipsum which looks reasonable. The generated\n",
    "    Lorem Ipsum is therefore always free from repetition, injected humour, or non-characteristic words etc.\n",
    "    \"\"\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the questions\n",
    "\n",
    "Here we apply the preprocessing and generation functions defined earlier. You may save questions into a list if your source is small. For large datasets we recommend adding some sort of checkpointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    [generate_questions(span) for span in preprocess(doc)] \n",
    "    for doc in tqdm(corpus)\n",
    "]\n",
    "\n",
    "questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate with Pandas\n",
    "\n",
    "Pandas is a very efficient way to aggregate the generations. In this example we define document, generation and question ids and group questions regarding these ids. We than count the unique examples for every span and document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>span_id</th>\n",
       "      <th>gen_id</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0:0</td>\n",
       "      <td>0:0:0</td>\n",
       "      <td>what is lorem ipsum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0:1</td>\n",
       "      <td>0:1:0</td>\n",
       "      <td>what is lorem ipsum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1:0</td>\n",
       "      <td>1:0:0</td>\n",
       "      <td>what is lorem ipsum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1:1</td>\n",
       "      <td>1:1:0</td>\n",
       "      <td>where does lorem ipsum come from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1:2</td>\n",
       "      <td>1:2:0</td>\n",
       "      <td>where does the word ipsum come from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1:3</td>\n",
       "      <td>1:3:0</td>\n",
       "      <td>what is lorem ipsum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1:4</td>\n",
       "      <td>1:4:0</td>\n",
       "      <td>what is lorem ipsum</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document_id span_id gen_id                             question\n",
       "0            0     0:0  0:0:0                  what is lorem ipsum\n",
       "1            0     0:1  0:1:0                  what is lorem ipsum\n",
       "2            1     1:0  1:0:0                  what is lorem ipsum\n",
       "3            1     1:1  1:1:0     where does lorem ipsum come from\n",
       "4            1     1:2  1:2:0  where does the word ipsum come from\n",
       "5            1     1:3  1:3:0                  what is lorem ipsum\n",
       "6            1     1:4  1:4:0                  what is lorem ipsum"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_df = pd.DataFrame([\n",
    "    dict(\n",
    "        document_id=doc_idx,\n",
    "        span_id=f\"{doc_idx}:{span_idx}\",\n",
    "        gen_id=f\"{doc_idx}:{span_idx}:{gen_idx}\",\n",
    "        question=question,\n",
    "    )\n",
    "    for doc_idx, document_gen in enumerate(questions)\n",
    "    for span_idx, span_gen in enumerate(document_gen)\n",
    "    for gen_idx, question in enumerate(span_gen)\n",
    "])\n",
    "\n",
    "question_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>span_id</th>\n",
       "      <th>gen_id</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>what is lorem ipsum</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where does lorem ipsum come from</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where does the word ipsum come from</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     document_id  span_id  gen_id  question\n",
       "question                                                                   \n",
       "what is lorem ipsum                            2        5       5         1\n",
       "where does lorem ipsum come from               1        1       1         1\n",
       "where does the word ipsum come from            1        1       1         1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group the results by question, count unique results and order by generation id counts.\n",
    "question_df \\\n",
    "    .groupby(\"question\") \\\n",
    "    .nunique() \\\n",
    "    .sort_values(\"gen_id\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our results suggest that the most frequent question in the corpus is `what is lorem ipsum` (on 2 documents and 5 spans). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
